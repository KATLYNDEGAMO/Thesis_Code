---
title: "PCM"
author: "Sarucam, Caryl Jay"
format: pdf
editor: visual
---

# Libraries for Possibilistic C-means
```{r message=FALSE, warning=FALSE}
# Libraries for Possibilistic C-means
library(readxl)
library(dplyr)
library(tidyr)
library(caret)
library(ggplot2)
library(factoextra)
library(cluster)
library(RColorBrewer)
library(ellipse)
library(reshape2)
library(ggrepel)

# Set seed for reproducibility
set.seed(123)
```

# Possibilistic C-Means Clustering Functions

#1.Loading Data Function

```{r}
# Load the dataset from the Excel file
data <- readxl::read_xlsx(path = "/cloud/project/ThePatient_Dataset.xlsx", sheet = 1)

head(data)
```

#2. Data Preprocessing Function
```{r message=FALSE, warning=FALSE}

# Store original row numbers for observation labels
row_ids <- rownames(data)


cap_outliers <- function(x) {
  if(is.numeric(x)) {
    qnt <- quantile(x, probs=c(.01, .99), na.rm = TRUE)
    x[x < qnt[1]] <- qnt[1]
    x[x > qnt[2]] <- qnt[2]
  }
  return(x)
}

# Select numeric columns 
data_numeric <- data %>%
  select(where(is.numeric)) %>%
  mutate(across(everything(), cap_outliers))

# Check for zero variance
var_values <- apply(data_numeric, 2, var)
zero_var_cols <- var_values == 0
if(any(zero_var_cols)) {
  cat("Removing", sum(zero_var_cols), "variables with zero variance\n")
  data_numeric <- data_numeric[, !zero_var_cols]
}

# Scale the data after removing zero variance columns
data_numeric <- scale(data_numeric)
  
# Check for any infinite or NA values
data_numeric <- data_numeric[is.finite(rowSums(data_numeric)),]

print(dim(data_numeric))
print(summary(data_numeric))
```

# 3. Finding Optimal Number of Clusters using the Elbow Method
```{r message=FALSE, warning=FALSE}
find_optimal_clusters_elbow <- function(data_matrix, max_k = NULL) {
  if (is.null(max_k)) {
    max_k <- min(10, ceiling(sqrt(nrow(data_matrix)/2)))
  }
  
  # Calculate WSS for different k values
  wss <- sapply(1:max_k, function(k) {
    kmeans(data_matrix, centers = k, nstart = 25)$tot.withinss
  })
  
  # Plot results
  wss_plot <- fviz_nbclust(data_matrix, kmeans, method = "wss") +
    theme(aspect.ratio = 0.7) +
    labs(title = "Elbow Method for Optimal k",
         subtitle = "Within Sum of Squares Method") +
    theme_bw(base_size = 12)
  
  # Determine optimal k using the elbow method
  wss_diff <- c(NA, diff(wss))
  wss_diff_rate <- c(NA, diff(wss) / wss[-1])
  

  threshold <- 0.2  
  candidate_k <- which(abs(wss_diff_rate) < threshold)[1]
  
  
  if (is.na(candidate_k)) {
    # Calculate second differences
    wss_second_diff <- c(NA, NA, diff(diff(wss)))
    candidate_k <- which.max(abs(wss_second_diff)) - 1
  }
  
  optimal_k <- min(candidate_k, max_k)
  
  # Create a data frame for plotting the results
  wss_df <- data.frame(
    k = 1:max_k,
    wss = wss,
    diff = c(NA, diff(wss)),
    diff_rate = c(NA, diff(wss) / wss[-1])
  )
  
  # Create a plot showing the elbow point
  elbow_plot <- ggplot(wss_df, aes(x = k, y = wss)) +
    geom_line(size = 1.2) +
    geom_point(size = 3) +
    geom_vline(xintercept = optimal_k, linetype = "dashed", color = "red", size = 1) +
    annotate("text", x = optimal_k + 0.3, y = max(wss) * 0.9, 
             label = paste("Optimal k =", optimal_k), 
             color = "red", size = 5, hjust = 0) +
    theme_bw(base_size = 12) +
    labs(title = "Determining the Optimal Number of Clusters",
         subtitle = "Elbow Method with Optimal k",
         x = "Number of Clusters (k)",
         y = "Within-Cluster Sum of Squares") +
    theme(plot.title = element_text(face = "bold"),
          aspect.ratio = 0.7)
  
  print(elbow_plot)
  
  return(list(
    optimal_k = optimal_k,
    wss_plot = wss_plot,
    elbow_plot = elbow_plot,
    wss = wss,
    wss_df = wss_df
  ))
}

# Find the optimal number of clusters using only the elbow method
cluster_info <- find_optimal_clusters_elbow(data_numeric)
cat("Optimal number of clusters:", cluster_info$optimal_k, "\n")

# Find optimal clusters using the Gap Statistic method
find_optimal_clusters_gap <- function(data_matrix, max_k = NULL) {
  if (is.null(max_k)) {
    max_k <- min(10, ceiling(sqrt(nrow(data_matrix)/3)))
  }
  

  gap_stat <- clusGap(data_matrix, FUN = function(x, k) kmeans(x, centers = k, nstart = 50), 
                      K.max = max_k, B = 100)
  
  # Extract gap statistic results
  gap_df <- as.data.frame(gap_stat$Tab)
  
  gap_values <- gap_df$gap
  gap_diffs <- c(NA, diff(gap_values))
  

  weighted_scores <- numeric(length(gap_values))
  for(i in 2:length(gap_values)) {
    weighted_scores[i] <- gap_values[i] + (gap_diffs[i] > 0) * 0.01
  }
  
  
  optimal_k 
  
  # Gap statistic plot
  gap_plot <- ggplot(gap_df, aes(x = 1:nrow(gap_df), y = gap)) +
    geom_line(size = 1.2) +
    geom_point(size = 3) +
    geom_errorbar(aes(ymin = gap - SE.sim, ymax = gap + SE.sim), width = 0.2) +
    geom_vline(xintercept = optimal_k, linetype = "dashed", color = "red", size = 1) +
    annotate("text", x = optimal_k + 0.3, y = max(gap_df$gap) * 0.9, 
             label = paste("Optimal k =", optimal_k), 
             color = "red", size = 5, hjust = 0) +
    theme_bw(base_size = 12) +
    labs(title = "Determining the Optimal Number of Clusters",
         subtitle = "Gap Statistic Method with Optimal k",
         x = "Number of Clusters (k)",
         y = "Gap Statistic") +
    theme(plot.title = element_text(face = "bold"),
          aspect.ratio = 0.7)
  
  print(gap_plot)
  
  return(list(
    optimal_k = optimal_k,
    gap_stat = gap_stat,
    gap_plot = gap_plot,
    gap_df = gap_df
  ))
}

# Find the optimal number of clusters using the gap statistic method
gap_cluster_info <- find_optimal_clusters_gap(data_numeric)
cat("Optimal number of clusters (Gap Statistic):", gap_cluster_info$optimal_k, "\n")

cat("Gap Statistic:", gap_cluster_info$optimal_k, "\n")

```


# 4. Possibilistic C-Means Algorithm Implementation
```{r message=FALSE, warning=FALSE}
# Implement PCM algorithm
run_pcm <- function(data_matrix, k, max_iter = 100, epsilon = 1e-6, eta_factor = 1.5) {
  # Run K-means for initial centroids
  set.seed(123)
  kmeans_init <- kmeans(data_matrix, centers = k, nstart = 25)
  centers <- kmeans_init$centers
  
  # Calculate initial distances
  dist_matrix <- matrix(0, nrow = nrow(data_matrix), ncol = k)
  for (i in 1:nrow(data_matrix)) {
    for (j in 1:k) {
      dist_matrix[i, j] <- sqrt(sum((data_matrix[i, ] - centers[j, ])^2))
    }
  }
  
  # Initialize fuzzy memberships for eta calculation
  fuzzy_memberships <- matrix(0, nrow = nrow(data_matrix), ncol = k)
  m <- 2  # Fuzziness parameter
  
  for (i in 1:nrow(data_matrix)) {
    for (j in 1:k) {
      num <- dist_matrix[i, j]
      if (num == 0) {
        fuzzy_memberships[i, ] <- 0
        fuzzy_memberships[i, j] <- 1
        break
      }
      denom <- sapply(1:k, function(k_idx) {
        (num / dist_matrix[i, k_idx])^(2/(m-1))
      })
      fuzzy_memberships[i, j] <- 1 / sum(denom)
    }
  }
  
  # Calculate eta parameters
  eta <- numeric(k)
  for (j in 1:k) {
    weighted_sum <- sum((fuzzy_memberships[, j]^m) * (dist_matrix[, j]^2))
    eta[j] <- weighted_sum / sum(fuzzy_memberships[, j]^m)
  }
  
  # Scale eta values for better separation
  eta <- eta * eta_factor
  
  # Initialize cluster values
  cluster <- matrix(0, nrow = nrow(data_matrix), ncol = k)
  for (i in 1:nrow(data_matrix)) {
    for (j in 1:k) {
      cluster[i, j] <- 1 / (1 + (dist_matrix[i, j]^2 / eta[j]))
    }
  }
  
  # PCM iteration
  iter_count <- 0
  converged <- FALSE
  start_time <- Sys.time()
  
  while (!converged && iter_count < max_iter) {
    iter_count <- iter_count + 1
    
    # convergence check
    old_centers <- centers
    
    # Update centers
    for (j in 1:k) {
      # Extract cluster values for cluster j
      typ_j <- cluster[, j]
      
      # Calculate weighted sum for each dimension
      weighted_sum <- matrix(0, nrow = 1, ncol = ncol(data_matrix))
      for (i in 1:nrow(data_matrix)) {
        weighted_sum <- weighted_sum + typ_j[i] * data_matrix[i, ]
      }
      
      # Calculate the denominator (sum of cluster values)
      denominator <- sum(typ_j)
      
      # Update center if denominator is not zero
      if (denominator > 0) {
        centers[j, ] <- weighted_sum / denominator
      }
    }
    
    # Recalculate distances
    for (i in 1:nrow(data_matrix)) {
      for (j in 1:k) {
        dist_matrix[i, j] <- sqrt(sum((data_matrix[i, ] - centers[j, ])^2))
      }
    }
    
    # Update cluster values
    for (i in 1:nrow(data_matrix)) {
      for (j in 1:k) {
        cluster[i, j] <- 1 / (1 + (dist_matrix[i, j]^2 / eta[j]))
      }
    }
    
    # Check for convergence
    center_diff <- max(abs(centers - old_centers))
    if (center_diff < epsilon) {
      converged <- TRUE
    }
    
    # Print progress every 10 iterations
    if (iter_count %% 10 == 0) {
      cat("Iteration:", iter_count, "Center difference:", center_diff, "\n")
    }
  }
  
  end_time <- Sys.time()
  execution_time <- difftime(end_time, start_time, units = "secs")
  
  cat("PCM converged after", iter_count, "iterations (", round(execution_time, 2), "seconds)\n")
  
  return(list(
    centers = centers,
    cluster = cluster,
    dist_matrix = dist_matrix,
    eta = eta,
    iterations = iter_count,
    execution_time = execution_time
  ))
}

# Run PCM with the optimal number of clusters
optimal_k <- cluster_info$optimal_k
pcm_results <- run_pcm(data_numeric, optimal_k)   
# Show the first few cluster values
head(pcm_results$cluster)
# Display centroids
pcm_results$centers
```

#5.  PCM Visualization
```{r message=FALSE, warning=FALSE}
visualize_pcm <- function(data_matrix, pcm_results, patient_ids, cluster_threshold = 0.3) {
  dim_reduction <- prcomp(data_matrix)
  reduced_data <- as.data.frame(dim_reduction$x[, 1:2])
  names(reduced_data) <- c("1", "2")
  reduced_data$row_id <- 1:nrow(reduced_data)
  reduced_data$observation <- 1:nrow(reduced_data)
  reduced_data$patient_id <- patient_ids
  
  centers_temp <- pcm_results$centers
  
  if (ncol(centers_temp) != ncol(data_matrix)) {
    if (ncol(centers_temp) < ncol(data_matrix)) {
      centers_padded <- matrix(0, nrow = nrow(centers_temp), ncol = ncol(data_matrix))
      centers_padded[, 1:ncol(centers_temp)] <- centers_temp
      centers_temp <- centers_padded
    } else {
      centers_temp <- centers_temp[, 1:ncol(data_matrix)]
    }
  }
  
  centers_centered <- t(t(centers_temp) - dim_reduction$center)
  centers_reduced <- as.data.frame(centers_centered %*% dim_reduction$rotation[, 1:2])
  
  names(centers_reduced) <- c("1", "2")
  centers_reduced$cluster <- 1:nrow(centers_reduced)
  
  k <- nrow(pcm_results$centers)
  
  if(!is.null(pcm_results$cluster) && is.matrix(pcm_results$cluster) && ncol(pcm_results$cluster) > 0) {
    cluster_df <- as.data.frame(pcm_results$cluster)
  } 
  else if(!is.null(pcm_results$typicality) && is.matrix(pcm_results$typicality) && ncol(pcm_results$typicality) > 0) {
    cluster_df <- as.data.frame(pcm_results$typicality)
  }
  else {
    cluster_df <- matrix(0, nrow = nrow(data_matrix), ncol = k)
    cluster_df <- as.data.frame(cluster_df)
  }
  
  names(cluster_df) <- paste0("cluster_", 1:k)
  cluster_df$row_id <- 1:nrow(cluster_df)
  
  plot_data <- merge(reduced_data, cluster_df, by = "row_id")
  
  plot_data$primary_cluster <- apply(plot_data[, grep("^cluster_", names(plot_data))], 1, which.max)
  
  unique_clusters <- unique(plot_data$primary_cluster)
  if (length(unique_clusters) < k) {
    for (i in 1:k) {
      if (!(i %in% unique_clusters)) {
        second_best <- apply(plot_data[, paste0("cluster_", 1:k)], 1, function(x) {
          sorted_idx <- order(x, decreasing = TRUE)
          return(sorted_idx[2] == i)
        })
        if (sum(second_best) > 0) {
          candidates <- which(second_best)
          cluster_diff <- numeric(length(candidates))
          for (j in 1:length(candidates)) {
            idx <- candidates[j]
            cluster_cols <- paste0("cluster_", 1:k)
            values <- unlist(plot_data[idx, cluster_cols])
            sorted_values <- sort(values, decreasing = TRUE)
            cluster_diff[j] <- sorted_values[1] - sorted_values[2]
          }
          num_to_reassign <- max(1, floor(length(candidates)*0.1))
          ordered_candidates <- candidates[order(cluster_diff)]
          to_reassign <- ordered_candidates[1:min(num_to_reassign, length(ordered_candidates))]
          plot_data$primary_cluster[to_reassign] <- i
        }
      }
    }
  }
  
  plot_data$max_cluster <- apply(plot_data[, grep("^cluster_", names(plot_data))], 1, max)
  plot_data$outlier_score <- 1 - plot_data$max_cluster
  
  if (k <= 2) {
    colors <- c("#E41A1C", "#4DAF4A")
  } else {
    colors <- brewer.pal(max(3, k), "Set1")
  }
  
  var_explained <- dim_reduction$sdev^2 / sum(dim_reduction$sdev^2) * 100
  
  exec_time <- round(as.numeric(pcm_results$execution_time), 2)
  
  calculate_ellipse <- function(cluster_num) {
    points <- plot_data[plot_data[, paste0("cluster_", cluster_num)] > 0.3, c("1", "2")]
    if(nrow(points) < 5) return(NULL)
    ellipse_points <- as.data.frame(
      ellipse::ellipse(
        x = cov(points),
        centre = colMeans(points),
        level = 0.95
      )
    )
    names(ellipse_points) <- c("1", "2")
    ellipse_points$cluster <- cluster_num
    return(ellipse_points)
  }
  
  ellipse_list <- lapply(1:k, calculate_ellipse)
  ellipses <- do.call(rbind, ellipse_list[!sapply(ellipse_list, is.null)])
  
  if(!is.null(ellipses)) {
    ellipses$cluster_factor <- factor(ellipses$cluster)
  }
  
  main_plot <- ggplot(plot_data, aes(x = `1`, y = `2`)) +
    {if(!is.null(ellipses))
      geom_path(data = ellipses,
                aes(x = `1`, y = `2`, color = factor(cluster), group = cluster),
                linetype = "dashed", size = 1.2, alpha = 0.8)
    } +
    geom_point(aes(color = factor(primary_cluster), size = max_cluster), alpha = 0.8) +
    geom_text_repel(aes(label = observation),
                   size = 3,
                   box.padding = 0.4,
                   point.padding = 0.2,
                   force = 4,
                   max.overlaps = 15,
                   min.segment.length = 0.2,
                   segment.alpha = 0.6) +
    geom_point(data = centers_reduced, aes(x = `1`, y = `2`),
               shape = 4, size = 10, color = "black", stroke = 2) +
    geom_text_repel(data = centers_reduced,
                   aes(label = paste("Centroid", cluster)),
                   size = 5, fontface = "bold",
                   box.padding = 1, force = 10,
                   point.padding = 0.5,
                   min.segment.length = 0.2) +
    scale_color_manual(values = colors, name = "Cluster") +
    scale_size_continuous(name = "Membership\nValue", range = c(2, 4)) +
    theme_bw(base_size = 12) +
    labs(title = paste("Possibilistic C-Means with", k, "Clusters"),
         subtitle = "Possibilistic C-Means ",
         x = NULL,
         y = NULL) +
    theme(axis.title.x = element_blank(),
          axis.title.y = element_blank(),
          axis.text.x = element_blank(),
          axis.text.y = element_blank(),
          legend.position = "right",
          plot.title = element_text(size = 14, face = "bold"),
          aspect.ratio = 0.85,
          plot.margin = margin(10, 20, 10, 10),
          panel.grid.minor = element_blank())
  
  outlier_threshold <- quantile(plot_data$outlier_score, 0.9)
  plot_data$is_outlier <- plot_data$outlier_score > outlier_threshold
  
  ellipse_data <- NULL
  if(!is.null(ellipses)) {
    ellipse_data <- ellipses
  }
  
  outlier_plot <- ggplot(plot_data, aes(x = `1`, y = `2`)) +
    geom_point(aes(color = outlier_score, size = outlier_score), alpha = 0.8) +
    scale_color_gradient(low = "green", high = "red", name = "Outlier\nScore") +
    scale_size_continuous(range = c(1, 6), name = "Outlier\nScore") +
    geom_text_repel(data = subset(plot_data, outlier_score > quantile(plot_data$outlier_score, 0.7)),
                   aes(label = patient_id), size = 3.5, box.padding = 0.5,
                   max.overlaps = 15, segment.color = "grey50",
                   min.segment.length = 0.1, force = 2) +
    geom_point(data = centers_reduced, aes(x = `1`, y = `2`),
               shape = 4, size = 6, color = "black", stroke = 1.5, alpha = 0.7) +
    theme_bw(base_size = 12) +
    labs(title = "Outlier Detection",
         subtitle = "Higher scores indicate potential outliers",
         x = NULL,
         y = NULL) +
    theme(axis.title.x = element_blank(),
          axis.title.y = element_blank(),
          axis.text.x = element_blank(),
          axis.text.y = element_blank(),
          aspect.ratio = 0.65)
  
  membership_df <- reshape2::melt(plot_data[, c("observation", paste0("cluster_", 1:k))],
                                 id.vars = "observation")
  membership_df$cluster <- as.numeric(gsub("cluster_", "", membership_df$variable))
  
  membership_df <- membership_df[order(membership_df$observation),]
  
  membership_plot <- ggplot(membership_df, aes(x = observation, y = value,
                                              color = factor(cluster), group = factor(cluster))) +
    geom_line(alpha = 0.7, size = 0.8) +
    geom_point(size = 2.5) +
    scale_color_manual(values = colors, name = "Cluster") +
    theme_bw(base_size = 12) +
    labs(title = "Membership Values by Observation",
         subtitle = "Shows membership degree of each observation to each cluster",
         x = NULL,
         y = NULL) +
    ylim(0, 1) +
    theme(legend.position = "right",
          axis.title.x = element_blank(),
          axis.title.y = element_blank(),
          axis.text.x = element_blank(),
          axis.text.y = element_blank(),
          aspect.ratio = 0.5,
          panel.grid.minor = element_blank())
  
  heatmap_data <- plot_data[, c("observation", paste0("cluster_", 1:k))]
  heatmap_data <- reshape2::melt(heatmap_data, id.vars = "observation", 
                               variable.name = "cluster", value.name = "membership")
  heatmap_data$cluster <- gsub("cluster_", "", heatmap_data$cluster)
  
  order_data <- plot_data[, c("observation", "primary_cluster")]
  order_data <- order_data[order(order_data$primary_cluster),]
  
  ordered_obs <- c()
  for (i in 1:k) {
    cluster_obs <- order_data$observation[order_data$primary_cluster == i]
    if (length(cluster_obs) > 0) {
      mem_values <- plot_data[plot_data$observation %in% cluster_obs, paste0("cluster_", i)]
      sorted_idx <- order(mem_values, decreasing = TRUE)
      ordered_cluster_obs <- cluster_obs[sorted_idx]
      ordered_obs <- c(ordered_obs, ordered_cluster_obs)
    }
  }
  
  heatmap_data$observation <- factor(heatmap_data$observation, 
                                   levels = ordered_obs)
  
  heatmap_data$cluster <- factor(heatmap_data$cluster, levels = as.character(1:k))
  
  heatmap_plot <- ggplot(heatmap_data, aes(x = cluster, y = observation, fill = membership)) +
    geom_tile() +
    scale_fill_gradient2(low = "white", mid = "blue", high = "violet", 
                        midpoint = 0.5, name = "Membership\nValue") +
    theme_minimal() +
    labs(title = "Membership Values Heatmap",
         subtitle = "Observations clustered by membership",
         x = NULL,
         y = NULL) +
    theme(axis.text.y = element_text(size = 7),
          axis.text.x = element_text(size = 10, face = "bold"),
          legend.position = "right",
          panel.grid = element_blank(),
          axis.title.x = element_blank(),
          axis.title.y = element_blank())
  
  return(list(
    main_plot = main_plot,
    outlier_plot = outlier_plot,
    membership_plot = membership_plot,
    heatmap_plot = heatmap_plot,
    plot_data = plot_data,
    centers_reduced = centers_reduced,
    ellipses = ellipses
  ))
}

row_numbers <- 1:nrow(data_numeric)

viz_results <- visualize_pcm(data_numeric, pcm_results, row_numbers)

print(viz_results$main_plot)
print(viz_results$outlier_plot)
print(viz_results$heatmap_plot)
```